{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8af48ca1-b6d1-4092-b7b5-037d3c2d7aef",
   "metadata": {
    "id": "8af48ca1-b6d1-4092-b7b5-037d3c2d7aef"
   },
   "source": [
    "# M4 | Research Investigation Notebook\n",
    "\n",
    "In this notebook, you will do a research investigation of your chosen dataset in teams. You will begin by formally selecting your research question (task 0), then processing your data (task 1), creating a predictive model (task 2), evaluating your model's results (task 3), and describing the contributions of each team member (task 4).\n",
    "\n",
    "For grading, please make sure your notebook has all cells run and is stored in your team's [Github Classroom repository](https://classroom.github.com/a/CNxME27U). You will also need to write a short, 2 page report about your design decisions as a team, to be stored in your repository. The Milestone 4 submission will be the contents of your repository at the due date (April 28 at 23:59 CET).\n",
    "\n",
    "## Brief overview of Lernnavi\n",
    "[Lernnavi](https://www.lernnavi.ch) is an instrument for promoting part of the basic technical study skills in German and mathematics.\n",
    "\n",
    "Lernnavi's dataset is formatted in three main tables:\n",
    "* ***users***: demographic information of users.\n",
    "* ***events***: events done by the users in the platform.\n",
    "* ***transactions***: question and answer solved by user.\n",
    "\n",
    "These table are described in detail in the [Milestone 2 data exploration notebook](https://github.com/epfl-ml4ed/mlbd-2023/blob/main/project/milestone-02/m2_lernnavi_sciper.ipynb). We have also provided access to a [test account to experiment with Lernnavi](https://moodle.epfl.ch/mod/forum/discuss.php?d=88094). \n",
    "\n",
    "You should provide arguments and justifications for all of your design decisions throughout this investigation. You can use your M3 responses as the basis for this discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82ea2d32-f0a9-4dc9-bb60-be43399f5b89",
   "metadata": {
    "id": "82ea2d32-f0a9-4dc9-bb60-be43399f5b89"
   },
   "outputs": [],
   "source": [
    "# Import the tables of the data set as dataframes.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "DATA_DIR = './data' # You many change the directory\n",
    "\n",
    "users = pd.read_csv('{}/users.csv.gz'.format(DATA_DIR))\n",
    "events = pd.read_csv('{}/events.csv.gz'.format(DATA_DIR))\n",
    "transactions = pd.read_csv('{}/transactions.csv.gz'.format(DATA_DIR))\n",
    "documents = pd.read_csv('{}/documents.csv.gz'.format(DATA_DIR))\n",
    "topics_translated = pd.read_csv('{}/topics_translated.csv'.format(DATA_DIR)).rename(columns={\"german_name\": \"challenge_name\"})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89137355",
   "metadata": {},
   "source": [
    "## Task 0: Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31dafc5b",
   "metadata": {},
   "source": [
    "**Research question:**\n",
    "Can we predict a user's mastery level in week N, by using the available data from week 1 to N-1?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a77f62b0-1945-48f1-8f22-5f6ebda1db8e",
   "metadata": {
    "id": "a77f62b0-1945-48f1-8f22-5f6ebda1db8e"
   },
   "source": [
    "## Task 1: Data Preprocessing\n",
    "\n",
    "As we will be predicting the mastery level of each user per week, we first need to parse the available mastery level data.\n",
    "\n",
    "We'll be using the NAVIGATE_DASHBOARD tasks to get the mastery level as we have found out that using the ACCEPT_PROGRESS and REJECT_PROGRESS gives us a lot less data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35350785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b633dbae579f48b5989413601d8ee753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing records:   0%|          | 0/1093791 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the total mastery as the sum of the mastery of all topics\n",
    "import json\n",
    "from tqdm import notebook as vis\n",
    "from numpy import mean as mean\n",
    "from numpy import sum as sum\n",
    "rows = []\n",
    "total = events[events['action']=='NAVIGATE_DASHBOARD'].shape[0]\n",
    "for index,row in vis.tqdm(events[events['action']=='NAVIGATE_DASHBOARD'].iterrows(), \n",
    "                          total=total, \n",
    "                          desc=\"Processing records\"):\n",
    "    json_loaded = json.loads(row['tracking_data'])\n",
    "    if(json_loaded['trackingDataType'] != 'DASHBOARD_VIEW_DATA'):\n",
    "        continue\n",
    "    title = json_loaded['dashboard']['title']\n",
    "    if(len(json_loaded['dashboard']['topics']) == 0):\n",
    "        continue\n",
    "    topics = json_loaded['dashboard']['topics']\n",
    "    total_mastery = []\n",
    "    total_diligence = []\n",
    "    for topic in topics:\n",
    "        children = topic['children']\n",
    "        for child in children:\n",
    "            total_mastery.append(topic['userData']['mastery'])\n",
    "            total_diligence.append(topic['userData']['diligence'])\n",
    "    user_id = row['user_id']\n",
    "    start_time = row.event_date\n",
    "    # add the row to the list\n",
    "    rows.append([user_id, title, sum(total_mastery), start_time, sum(total_diligence)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "303a9b52",
   "metadata": {},
   "source": [
    "The below cell is commented out for the reason we have described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62c0d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import notebook as vis\n",
    "# rows2 = []\n",
    "# total = events[(events['action']=='ACCEPT_PROGRESS') | (events['action'] == 'REJECT_PROGRESS')].shape[0]\n",
    "# for index,row in vis.tqdm(events[(events['action']=='ACCEPT_PROGRESS') | (events['action'] == 'REJECT_PROGRESS')].iterrows(),\n",
    "#                           total=total,\n",
    "#                           desc=\"Processing records\"):\n",
    "#     json_loaded = json.loads(row['tracking_data'])\n",
    "#     topics = json_loaded['sessionEndScreenTopics']\n",
    "#     for topic in topics:\n",
    "#         rows2.append([row['user_id'], topic['topic']['name'], topic['newMastery'], row['event_date']])\n",
    "# print(rows2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74f15fbd",
   "metadata": {},
   "source": [
    "After parsing the mastery level data we have a list of the following form (user_id, title, mastery, timestamp)\n",
    "\n",
    "Now we transform this into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b587336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe from the list\n",
    "mastery_df = pd.DataFrame(rows, columns=['user_id', 'title', 'mastery', 'start_time' , 'diligence'])\n",
    "# Find the earliest start time for each user in events table\n",
    "earliest_start_time = events.groupby('user_id').event_date.min().reset_index()\n",
    "# rename column to min_start_time\n",
    "earliest_start_time = earliest_start_time.rename(columns={'event_date': 'min_start_time'})\n",
    "# merge with earliest_transaction\n",
    "mastery_df = mastery_df.merge(earliest_start_time, on='user_id', how='left')\n",
    "# convert start_time to datetime\n",
    "mastery_df.start_time = pd.to_datetime(mastery_df.start_time)\n",
    "# convert earliest_transaction to datetime\n",
    "mastery_df.min_start_time = pd.to_datetime(mastery_df.min_start_time)\n",
    "# calculate the number of weeks since first transaction\n",
    "mastery_df['weeks_since_first_transaction'] = (mastery_df.start_time - mastery_df.min_start_time).dt.days//7\n",
    "# drop the columns start_time and min_start_time\n",
    "mastery_df = mastery_df.drop(columns=['start_time','min_start_time'])\n",
    "# A user can check their mastery multiple times a week,\n",
    "# Find the max mastery for each user in each week, and find the max diligence for each user in each week\n",
    "# Keep those rows and drop the rest\n",
    "mastery_df = mastery_df.groupby(['user_id','title','weeks_since_first_transaction']).agg({'mastery': 'max', 'diligence': 'max'}).reset_index()\n",
    "# Multiply mastery col by 10 as explained in the data metadata file\n",
    "mastery_df.mastery = mastery_df.mastery*10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e8b8520",
   "metadata": {},
   "source": [
    "Mastery level for each user is different per topic, the 3 main topics that encompasses all other subtopics are Orthografie, Mathematik and Deutsch. We drop Orthografie for having almost no data related to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de9b6a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deutsch' 'Mathematik' 'Orthografie']\n",
      "Orthografie: (6, 5)\n",
      "Mathematik: (34981, 5)\n",
      "Deutsch: (44648, 5)\n"
     ]
    }
   ],
   "source": [
    "print(mastery_df.title.unique())\n",
    "print('Orthografie: ' + str(mastery_df[mastery_df.title == 'Orthografie'].shape))\n",
    "print('Mathematik: ' + str(mastery_df[mastery_df.title == 'Mathematik'].shape))\n",
    "print('Deutsch: ' + str(mastery_df[mastery_df.title == 'Deutsch'].shape))\n",
    "# Notice Orthografie has almost no rows.\n",
    "# Drop rows that have title as 'Orthografie'\n",
    "mastery_df = mastery_df[mastery_df.title != 'Orthografie']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f75eccdb",
   "metadata": {},
   "source": [
    "We split our data frame to two, one for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0132a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mastery_df_german = mastery_df[mastery_df['title'] == \"Deutsch\"]\n",
    "mastery_df_math = mastery_df[mastery_df['title'] == \"Mathematik\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e14669ca",
   "metadata": {},
   "source": [
    "Now we have our initial table, we need to add some features to it so that it's suitable to be trained by an ML model.\n",
    "\n",
    "The below cell adds the following features: \n",
    "    1. Weekly solved question count\n",
    "    2. Weekly percentage of CORRECTLY solved questions, where partially correct questions count as 0.5 correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b88b5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will add extra features to this table\n",
    "\"\"\"\n",
    "    CREATE THE TABLE\n",
    "\"\"\"\n",
    "new_transactions = transactions[['transaction_token','evaluation', 'document_id']]\n",
    "new_events = events[['user_id', 'transaction_token', 'event_date', 'action']]\n",
    "new_transactions = new_transactions.merge(new_events, on='transaction_token', how='right')\n",
    "new_transactions = new_transactions.merge(earliest_start_time, on='user_id', how='left')\n",
    "new_transactions.event_date = pd.to_datetime(new_transactions.event_date)\n",
    "new_transactions.min_start_time = pd.to_datetime(new_transactions.min_start_time)\n",
    "new_transactions['weeks_since_first_transaction'] = (new_transactions['event_date'] - new_transactions['min_start_time']).dt.days // 7\n",
    "\n",
    "\"\"\"\n",
    "    FIND WEEKLY EVENT COUNT\n",
    "\"\"\"\n",
    "# Removed event counts as it's hard to distinguish events between different topics.\n",
    "# Find the number of transactions for each user in each week\n",
    "#num_events_weekly = new_transactions.groupby(['user_id','weeks_since_first_transaction']).action.count().reset_index()\n",
    "# Rename the column to num_events\n",
    "#num_events_weekly = num_events_weekly.rename(columns={'action': 'num_events'})\n",
    "\n",
    "\"\"\"\n",
    "    FIND WEEKLY QUESTIONS SOLVED\n",
    "\"\"\"\n",
    "# Only consider question answering events (action = 'SUBMIT_ANSWER')\n",
    "num_questions_weekly = new_transactions[new_transactions.action == 'SUBMIT_ANSWER']\n",
    "num_questions_weekly = num_questions_weekly.dropna(subset = [\"document_id\"])\n",
    "doc_to_topic = documents.merge(topics_translated, how='left', left_on='topic_id', right_on='id')[['document_id','math']]\n",
    "doc_to_topic = doc_to_topic.drop_duplicates(\"document_id\")\n",
    "num_questions_weekly = num_questions_weekly.merge(doc_to_topic, how = 'left', on='document_id')\n",
    "\n",
    "#Drop rows with math = NaN\n",
    "num_questions_weekly = num_questions_weekly[num_questions_weekly['math'].notna()]\n",
    "\n",
    "#Create german dataframe\n",
    "num_questions_weekly_german = num_questions_weekly[num_questions_weekly['math'] == 0]\n",
    "#Create math dataframe\n",
    "num_questions_weekly_math = num_questions_weekly[num_questions_weekly['math'] == 1]\n",
    "# Count the number of questions for each user in each week\n",
    "num_questions_weekly_german = num_questions_weekly_german.groupby(['user_id','weeks_since_first_transaction']).action.count().reset_index()\n",
    "num_questions_weekly_math = num_questions_weekly_math.groupby(['user_id','weeks_since_first_transaction']).action.count().reset_index()\n",
    "\n",
    "# Rename column to num_questions\n",
    "num_questions_weekly_math = num_questions_weekly_math.rename(columns={'action': 'num_questions'})\n",
    "num_questions_weekly_german = num_questions_weekly_german.rename(columns={'action': 'num_questions'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7e331cc",
   "metadata": {},
   "source": [
    "Now that we have the weekly number of questions solved for both german and mathematics, we tried to see if we have been able to capture all the questions solved(i.e. have we lost any data in the process of trying to split questions between topics?)\n",
    "\n",
    "To do this:\n",
    "\n",
    "We create the same dataframes again, but this time WITHOUT splitting it by topic, and calculate the number of TOTAL questions solved per week per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1619c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions_for_comparison = transactions[['transaction_token','evaluation', 'document_id']]\n",
    "new_events_for_comparison = events[['user_id', 'transaction_token', 'event_date', 'action']]\n",
    "new_transactions_for_comparison = new_transactions_for_comparison.merge(new_events_for_comparison, on='transaction_token', how='right')\n",
    "new_transactions_for_comparison = new_transactions_for_comparison.merge(earliest_start_time, on='user_id', how='left')\n",
    "new_transactions_for_comparison.event_date = pd.to_datetime(new_transactions_for_comparison.event_date)\n",
    "new_transactions_for_comparison.min_start_time = pd.to_datetime(new_transactions_for_comparison.min_start_time)\n",
    "new_transactions_for_comparison['weeks_since_first_transaction'] = (new_transactions_for_comparison['event_date'] - new_transactions_for_comparison['min_start_time']).dt.days // 7\n",
    "\n",
    "num_questions_weekly_orig = new_transactions_for_comparison[new_transactions.action == 'SUBMIT_ANSWER']\n",
    "num_questions_weekly_orig = num_questions_weekly_orig.merge(doc_to_topic, how = 'left', on='document_id')\n",
    "nan_math_count = num_questions_weekly_orig.math.isna().sum()\n",
    "num_questions_weekly_orig = num_questions_weekly_orig.groupby(['user_id','weeks_since_first_transaction']).action.count().reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69a5c780",
   "metadata": {},
   "source": [
    "Now below we get per user and per week the number of TOTAL questions solved(column name = action) and the amount of german questions solved and amount of math questions solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "007e1bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>weeks_since_first_transaction</th>\n",
       "      <th>action</th>\n",
       "      <th>german_questions</th>\n",
       "      <th>math_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>387604</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>387604</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>387604</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>387604</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>387604</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  weeks_since_first_transaction  action  german_questions  \\\n",
       "0   387604                             14       1               1.0   \n",
       "1   387604                             17       4               4.0   \n",
       "2   387604                             18       2               2.0   \n",
       "3   387604                             19       1               1.0   \n",
       "4   387604                             21       1               1.0   \n",
       "\n",
       "   math_questions  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "math_german_compared = num_questions_weekly_german.merge(num_questions_weekly_math, how = 'outer', on=['user_id','weeks_since_first_transaction'])\n",
    "math_german_compared = math_german_compared.rename(columns={'num_questions_x': 'german_questions', 'num_questions_y': 'math_questions'})\n",
    "math_german_compared = math_german_compared.fillna(value={'math_questions': 0, 'german_questions': 0})\n",
    "question_comparison=num_questions_weekly_orig.merge(math_german_compared, how='left', on=['user_id','weeks_since_first_transaction'])\n",
    "question_comparison=question_comparison.fillna(0)\n",
    "question_comparison.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0439c07a",
   "metadata": {},
   "source": [
    "Below we find the rows where the amount of german questions + amount of math questions is not equal to the total amount of questions solved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1414e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>weeks_since_first_transaction</th>\n",
       "      <th>action</th>\n",
       "      <th>german_questions</th>\n",
       "      <th>math_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>387604</td>\n",
       "      <td>50</td>\n",
       "      <td>33</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>387605</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>387605</td>\n",
       "      <td>14</td>\n",
       "      <td>58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>387605</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>387605</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65401</th>\n",
       "      <td>431353</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65402</th>\n",
       "      <td>431354</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65404</th>\n",
       "      <td>431355</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65561</th>\n",
       "      <td>431656</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65568</th>\n",
       "      <td>431677</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3734 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  weeks_since_first_transaction  action  german_questions  \\\n",
       "20      387604                             50      33              32.0   \n",
       "29      387605                              6      50              29.0   \n",
       "32      387605                             14      58              29.0   \n",
       "33      387605                             16      48              23.0   \n",
       "38      387605                             32      20              14.0   \n",
       "...        ...                            ...     ...               ...   \n",
       "65401   431353                              1      12               0.0   \n",
       "65402   431354                              1      21               0.0   \n",
       "65404   431355                              2      21               0.0   \n",
       "65561   431656                              0      22               0.0   \n",
       "65568   431677                              0      18               0.0   \n",
       "\n",
       "       math_questions  \n",
       "20                0.0  \n",
       "29               17.0  \n",
       "32               22.0  \n",
       "33               23.0  \n",
       "38                0.0  \n",
       "...               ...  \n",
       "65401            11.0  \n",
       "65402            20.0  \n",
       "65404            20.0  \n",
       "65561            21.0  \n",
       "65568            17.0  \n",
       "\n",
       "[3734 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_equal_rows = question_comparison[question_comparison.action != question_comparison.german_questions + question_comparison.math_questions]\n",
    "not_equal_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "386eb55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>weeks_since_first_transaction</th>\n",
       "      <th>action</th>\n",
       "      <th>german_questions</th>\n",
       "      <th>math_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>387604</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>387604</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>387604</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>387604</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>387604</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65730</th>\n",
       "      <td>431999</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65731</th>\n",
       "      <td>432001</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65732</th>\n",
       "      <td>432014</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65733</th>\n",
       "      <td>432016</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65734</th>\n",
       "      <td>432020</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62001 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  weeks_since_first_transaction  action  german_questions  \\\n",
       "0       387604                             14       1               1.0   \n",
       "1       387604                             17       4               4.0   \n",
       "2       387604                             18       2               2.0   \n",
       "3       387604                             19       1               1.0   \n",
       "4       387604                             21       1               1.0   \n",
       "...        ...                            ...     ...               ...   \n",
       "65730   431999                              0       4               0.0   \n",
       "65731   432001                              0       6               0.0   \n",
       "65732   432014                              0       9               0.0   \n",
       "65733   432016                              0       5               0.0   \n",
       "65734   432020                              0       7               0.0   \n",
       "\n",
       "       math_questions  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "65730             4.0  \n",
       "65731             6.0  \n",
       "65732             9.0  \n",
       "65733             5.0  \n",
       "65734             7.0  \n",
       "\n",
       "[62001 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_comparison[question_comparison.action == question_comparison.german_questions + question_comparison.math_questions]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1b3b212",
   "metadata": {},
   "source": [
    "We notice there are 62001 rows where the equality does hold and 3734 rows where the equality does not hold and most of the rows only differ in only a couple of questions. Now we find the total amount of questions missing: Which is equal to 6282."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0b53acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6282.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(question_comparison['action'] - question_comparison['german_questions'] - question_comparison['math_questions']).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3eb1009",
   "metadata": {},
   "source": [
    "Because in german_questions and math_questions we only consider the rows that have math column as 0 or 1, we don't consider the math columns that have the value NaN, and there are in total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23e49008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6282"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_math_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5e0ba95",
   "metadata": {},
   "source": [
    "And this is where our difference comes in. As this is not something we can fix as this is due to some rows having missing data, we accept this data loss as it's within acceptible range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d7ff6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    FIND WEEKLY CORRECT QUESTIONS SOLVED\n",
    "\"\"\"\n",
    "# Only consider question answering events that are correct (evaluation = 'CORRECT')\n",
    "num_correct_weekly = new_transactions[(new_transactions.evaluation == 'CORRECT') & (new_transactions.action == 'SUBMIT_ANSWER')]\n",
    "#Merge with documents and topics to separate german and math\n",
    "num_correct_weekly = num_correct_weekly.merge(doc_to_topic, how = 'left', on='document_id')\n",
    "#Drop rows with math = NaN\n",
    "num_correct_weekly = num_correct_weekly[num_correct_weekly['math'].notna()]\n",
    "\n",
    "#Create german dataframe\n",
    "num_correct_weekly_german = num_correct_weekly.query('math == 0')\n",
    "#Create math dataframe\n",
    "num_correct_weekly_math = num_correct_weekly.query('math == 1')\n",
    "\n",
    "# Count the number of questions for each user in each week\n",
    "num_correct_weekly_german = num_correct_weekly_german.groupby(['user_id','weeks_since_first_transaction']).action.count().reset_index()\n",
    "num_correct_weekly_math = num_correct_weekly_math.groupby(['user_id','weeks_since_first_transaction']).action.count().reset_index()\n",
    "\n",
    "# Rename column to num_questions\n",
    "num_correct_weekly_math = num_correct_weekly_math.rename(columns={'action': 'num_correct'})\n",
    "num_correct_weekly_german = num_correct_weekly_german.rename(columns={'action': 'num_correct'})\n",
    "\n",
    "\"\"\"\n",
    "    FIND WEEKLY PARTIALLY CORRECT QUESTIONS SOLVED\n",
    "\"\"\"\n",
    "# Only consider question answering events that are correct (evaluation = 'PARTIAL')\n",
    "num_partial_weekly = new_transactions[(new_transactions.evaluation == 'PARTIAL') & (new_transactions.action == 'SUBMIT_ANSWER')]\n",
    "num_partial_weekly = num_partial_weekly.merge(doc_to_topic, how = 'left', on='document_id')\n",
    "#Drop rows with math = NaN\n",
    "num_partial_weekly = num_partial_weekly[num_partial_weekly['math'].notna()]\n",
    "\n",
    "#Create german dataframe\n",
    "num_partial_weekly_german = num_partial_weekly.query('math == 0')\n",
    "#Create math dataframe\n",
    "num_partial_weekly_math = num_partial_weekly.query('math == 1')\n",
    "\n",
    "# Count the number of questions for each user in each week\n",
    "num_partial_weekly_german = num_partial_weekly_german.groupby(['user_id','weeks_since_first_transaction']).action.count().reset_index()\n",
    "num_partial_weekly_math = num_partial_weekly_math.groupby(['user_id','weeks_since_first_transaction']).action.count().reset_index()\n",
    "\n",
    "# Rename column to num_questions\n",
    "num_partial_weekly_math = num_partial_weekly_math.rename(columns={'action': 'num_partial'})\n",
    "num_partial_weekly_german = num_partial_weekly_german.rename(columns={'action': 'num_partial'})\n",
    "\n",
    "\n",
    "# Merge the three tables together for german\n",
    "num_questions_weekly_german = num_questions_weekly_german.merge(num_correct_weekly_german, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "num_questions_weekly_german = num_questions_weekly_german.merge(num_partial_weekly_german, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "num_questions_weekly_german.fillna(0, inplace=True)\n",
    "\n",
    "# Merge the three tables together for math\n",
    "num_questions_weekly_math = num_questions_weekly_math.merge(num_correct_weekly_math, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "num_questions_weekly_math = num_questions_weekly_math.merge(num_partial_weekly_math, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "num_questions_weekly_math.fillna(0, inplace=True)\n",
    "\n",
    "# Create new column percentage_correct = (num_correct +0.5*num_partial)/ num_questions\n",
    "num_questions_weekly_german['percentage_correct'] = 100 * (num_questions_weekly_german.num_correct + 0.5*num_questions_weekly_german.num_partial)/num_questions_weekly_german.num_questions\n",
    "# Drop the columns num_correct and num_partial\n",
    "num_questions_weekly_german = num_questions_weekly_german.drop(columns=['num_correct','num_partial'])\n",
    "\n",
    "# Create new column percentage_correct = (num_correct +0.5*num_partial)/ num_questions\n",
    "num_questions_weekly_math['percentage_correct'] = 100 * (num_questions_weekly_math.num_correct + 0.5*num_questions_weekly_math.num_partial)/num_questions_weekly_math.num_questions\n",
    "# Drop the columns num_correct and num_partial\n",
    "num_questions_weekly_math = num_questions_weekly_math.drop(columns=['num_correct','num_partial'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80159390",
   "metadata": {},
   "source": [
    "The below cell adds the following features:\n",
    "    1. Review task count\n",
    "    2. View task count\n",
    "    3. Window visible ratio\n",
    "\n",
    "Do note that in the data the names for these actions are reversed, i.e. the VIEW_QUESTION corresponds to reviewing a task and REVIEW_TASK corresponds to viewing a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "daee86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    FIND THE REVIEW TASK COUNT\n",
    "\"\"\"\n",
    "# Only consider question answering events (action = 'SUBMIT_ANSWER')\n",
    "num_review_weekly = new_transactions[new_transactions.action == 'VIEW_QUESTION']\n",
    "num_review_weekly = num_review_weekly.dropna(subset = [\"document_id\"])\n",
    "num_review_weekly = num_review_weekly.merge(doc_to_topic, how = 'left', on='document_id')\n",
    "#Drop rows with math = NaN\n",
    "num_review_weekly = num_review_weekly[num_review_weekly['math'].notna()]\n",
    "\n",
    "#Create german dataframe\n",
    "num_review_weekly_german = num_review_weekly.query('math == 0')\n",
    "#Create math dataframe\n",
    "num_review_weekly_math = num_review_weekly.query('math == 1')\n",
    "# Count the number of questions for each user in each week\n",
    "num_review_weekly_german = num_review_weekly_german.groupby(['user_id','weeks_since_first_transaction']).action.count().reset_index()\n",
    "num_review_weekly_math = num_review_weekly_math.groupby(['user_id','weeks_since_first_transaction']).action.count().reset_index()\n",
    "\n",
    "# Rename column to num_review\n",
    "num_review_weekly_math = num_review_weekly_math.rename(columns={'action': 'num_review'})\n",
    "num_review_weekly_german = num_review_weekly_german.rename(columns={'action': 'num_review'})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    FIND THE VIEW COUNT\n",
    "\"\"\"\n",
    "# Only consider question answering events (action = 'SUBMIT_ANSWER')\n",
    "num_view_weekly = new_transactions[new_transactions.action == 'REVIEW_TASK']\n",
    "num_view_weekly = num_view_weekly.dropna(subset = [\"document_id\"])\n",
    "num_view_weekly = num_view_weekly.merge(doc_to_topic, how = 'left', on='document_id')\n",
    "#Drop rows with math = NaN\n",
    "num_view_weekly = num_view_weekly[num_view_weekly['math'].notna()]\n",
    "\n",
    "#Create german dataframe\n",
    "num_view_weekly_german = num_view_weekly.query('math == 0')\n",
    "#Create math dataframe\n",
    "num_view_weekly_math = num_view_weekly.query('math == 1')\n",
    "\n",
    "# Count the number of questions for each user in each week\n",
    "num_view_weekly_german = num_view_weekly_german.groupby(['user_id','weeks_since_first_transaction']).action.count().reset_index()\n",
    "num_view_weekly_math = num_view_weekly_math.groupby(['user_id','weeks_since_first_transaction']).action.count().reset_index()\n",
    "\n",
    "# Rename column to num_review\n",
    "num_view_weekly_math = num_view_weekly_math.rename(columns={'action': 'num_view'})\n",
    "num_view_weekly_german = num_view_weekly_german.rename(columns={'action': 'num_view'})\n",
    "\n",
    "\"\"\"\n",
    "FIND THE WINDOW VISIBLE RATIO FOR EACH USER\n",
    "\"\"\"\n",
    "\n",
    "# in the events table for each user find the count of action='WINDOW_VISIBLE_FALSE'\n",
    "# and action='WINDOW_VISIBLE_TRUE'\n",
    "# and then calculate the ratio of WINDOW_VISIBLE_TRUE / (WINDOW_VISIBLE_TRUE + WINDOW_VISIBLE_FALSE)\n",
    "\n",
    "# drop all rows except those with action = 'WINDOW_VISIBLE_FALSE'\n",
    "temp = new_transactions[new_transactions.action == 'WINDOW_VISIBLE_FALSE']\n",
    "\n",
    "# count the number of rows for each user\n",
    "num_window_visible_false = temp.groupby(['user_id','weeks_since_first_transaction']).action.count()\n",
    "# fill the missing user ids with 0\n",
    "num_window_visible_false = num_window_visible_false.to_frame().fillna(0).reset_index()\n",
    "# drop all rows except those with action = 'WINDOW_VISIBLE_TRUE'\n",
    "temp = new_transactions[new_transactions.action == 'WINDOW_VISIBLE_TRUE']\n",
    "\n",
    "# count the number of rows for each user\n",
    "num_window_visible_true = temp.groupby(['user_id','weeks_since_first_transaction']).action.count()\n",
    "\n",
    "# fill the missing user ids with 0\n",
    "num_window_visible_true = num_window_visible_true.to_frame().fillna(0).reset_index()\n",
    "\n",
    "# Create a new dataframe with 2 columns: user_id and the ratio\n",
    "df_window_visible = pd.DataFrame({'user_id': num_window_visible_true.user_id, 'weeks_since_first_transaction': num_window_visible_true.weeks_since_first_transaction, 'ratio_window_visible': num_window_visible_true.action / (num_window_visible_true.action + num_window_visible_false.action)})\n",
    "\n",
    "\"\"\"\n",
    "    MERGE ALL THE TABLES\n",
    "\"\"\"\n",
    "# Merge the tables together for german\n",
    "#mastery_df = mastery_df.merge(num_events_weekly, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "mastery_df_german = mastery_df_german.merge(num_questions_weekly_german, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "mastery_df_german = mastery_df_german.merge(num_review_weekly_german, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "mastery_df_german = mastery_df_german.merge(num_view_weekly_german, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "mastery_df_german = mastery_df_german.merge(df_window_visible, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "# Fill the NaN values in num_question and num_events with 0\n",
    "mastery_df_german[['num_questions', 'num_review']] = mastery_df_german[['num_questions', 'num_review']].fillna(0)\n",
    "\n",
    "# Merge the tables together for math\n",
    "#mastery_df = mastery_df.merge(num_events_weekly, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "mastery_df_math = mastery_df_math.merge(num_questions_weekly_math, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "mastery_df_math = mastery_df_math.merge(num_review_weekly_math, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "mastery_df_math = mastery_df_math.merge(num_view_weekly_math, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "mastery_df_math = mastery_df_math.merge(df_window_visible, on=['user_id','weeks_since_first_transaction'], how='left')\n",
    "# Fill the NaN values in num_question and num_events with 0\n",
    "mastery_df_math[['num_questions', 'num_review']] = mastery_df_math[['num_questions', 'num_review']].fillna(0)\n",
    "\n",
    "#mastery_df_german[\"num_questions\"] = mastery_df_german[\"num_questions\"].astype(int)\n",
    "#mastery_df[\"num_math_questions\"] = mastery_df[\"num_math_questions\"].as\"ype(int)\n",
    "#mastery_df[\"num_deutsch_questions\"] = mastery_df[\"num_deutsch_questions\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ffa21869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>weeks_since_first_transaction</th>\n",
       "      <th>mastery</th>\n",
       "      <th>diligence</th>\n",
       "      <th>num_questions</th>\n",
       "      <th>percentage_correct</th>\n",
       "      <th>num_review</th>\n",
       "      <th>num_view</th>\n",
       "      <th>ratio_window_visible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>387604</td>\n",
       "      <td>Mathematik</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>387604</td>\n",
       "      <td>Mathematik</td>\n",
       "      <td>54</td>\n",
       "      <td>1.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>387604</td>\n",
       "      <td>Mathematik</td>\n",
       "      <td>64</td>\n",
       "      <td>1.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>387604</td>\n",
       "      <td>Mathematik</td>\n",
       "      <td>75</td>\n",
       "      <td>1.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>387605</td>\n",
       "      <td>Mathematik</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>387605</td>\n",
       "      <td>Mathematik</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>387605</td>\n",
       "      <td>Mathematik</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3970.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>76.470588</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.860465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>387605</td>\n",
       "      <td>Mathematik</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3970.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>387605</td>\n",
       "      <td>Mathematik</td>\n",
       "      <td>11</td>\n",
       "      <td>50.165633</td>\n",
       "      <td>4144.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>387605</td>\n",
       "      <td>Mathematik</td>\n",
       "      <td>13</td>\n",
       "      <td>51.058490</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       title  weeks_since_first_transaction    mastery  diligence  \\\n",
       "0   387604  Mathematik                              5   0.000000        0.0   \n",
       "1   387604  Mathematik                             54   1.041667        0.0   \n",
       "2   387604  Mathematik                             64   1.041667        0.0   \n",
       "3   387604  Mathematik                             75   1.041667        0.0   \n",
       "4   387605  Mathematik                              3   0.000000     3550.0   \n",
       "5   387605  Mathematik                              4   0.000000     3550.0   \n",
       "6   387605  Mathematik                              6   0.000000     3970.0   \n",
       "7   387605  Mathematik                              8   0.000000     3970.0   \n",
       "8   387605  Mathematik                             11  50.165633     4144.0   \n",
       "9   387605  Mathematik                             13  51.058490     4216.0   \n",
       "\n",
       "   num_questions  percentage_correct  num_review  num_view  \\\n",
       "0            0.0                 NaN         5.0       NaN   \n",
       "1            3.0           33.333333         0.0      12.0   \n",
       "2            0.0                 NaN         0.0       NaN   \n",
       "3            0.0                 NaN         0.0       NaN   \n",
       "4            1.0           50.000000         2.0       NaN   \n",
       "5            0.0                 NaN         1.0       NaN   \n",
       "6           17.0           76.470588        30.0      15.0   \n",
       "7            0.0                 NaN         0.0       2.0   \n",
       "8            6.0           50.000000         0.0      11.0   \n",
       "9            8.0           56.250000         2.0       9.0   \n",
       "\n",
       "   ratio_window_visible  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2              0.625000  \n",
       "3              0.500000  \n",
       "4                   NaN  \n",
       "5                   NaN  \n",
       "6              0.860465  \n",
       "7              0.357143  \n",
       "8              0.545455  \n",
       "9              0.937500  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mastery_df_math.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e9b822a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>weeks_since_first_transaction</th>\n",
       "      <th>mastery</th>\n",
       "      <th>diligence</th>\n",
       "      <th>num_questions</th>\n",
       "      <th>percentage_correct</th>\n",
       "      <th>num_review</th>\n",
       "      <th>num_view</th>\n",
       "      <th>ratio_window_visible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>387604</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>387604</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>387604</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>387604</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>387604</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>387604</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>387604</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>387604</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>387604</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>19</td>\n",
       "      <td>0.173611</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>387604</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>23</td>\n",
       "      <td>0.173611</td>\n",
       "      <td>258.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    title  weeks_since_first_transaction   mastery  diligence  \\\n",
       "0   387604  Deutsch                             10  0.000000        0.0   \n",
       "1   387604  Deutsch                             11  0.000000        0.0   \n",
       "2   387604  Deutsch                             12  0.000000        0.0   \n",
       "3   387604  Deutsch                             13  0.000000        0.0   \n",
       "4   387604  Deutsch                             14  0.000000        0.0   \n",
       "5   387604  Deutsch                             15  0.000000        0.0   \n",
       "6   387604  Deutsch                             16  0.000000        0.0   \n",
       "7   387604  Deutsch                             17  0.000000        8.0   \n",
       "8   387604  Deutsch                             19  0.173611       68.0   \n",
       "9   387604  Deutsch                             23  0.173611      258.0   \n",
       "\n",
       "   num_questions  percentage_correct  num_review  num_view  \\\n",
       "0            0.0                 NaN         0.0       NaN   \n",
       "1            0.0                 NaN         0.0       NaN   \n",
       "2            0.0                 NaN         0.0       1.0   \n",
       "3            0.0                 NaN         0.0       NaN   \n",
       "4            1.0                 0.0         0.0      15.0   \n",
       "5            0.0                 NaN         0.0       3.0   \n",
       "6            0.0                 NaN         0.0       NaN   \n",
       "7            4.0                12.5         0.0       7.0   \n",
       "8            1.0                50.0         0.0       1.0   \n",
       "9            8.0                50.0         6.0      19.0   \n",
       "\n",
       "   ratio_window_visible  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2              0.909091  \n",
       "3              0.900000  \n",
       "4              0.645161  \n",
       "5              0.214286  \n",
       "6              0.086957  \n",
       "7              0.555556  \n",
       "8              0.157895  \n",
       "9              0.583333  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mastery_df_german.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3013d690",
   "metadata": {},
   "source": [
    "Notice that the current week definition does not bode well with the data, the first week for some users are not week 0(user 387604) because we have split the data into math and german, then there are missing weeks(51 weeks missing for user 387615), because this user has been absent from the platform for a really long time.\n",
    "\n",
    "See the below cell output for examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24af071c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>weeks_since_first_transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>387604</td>\n",
       "      <td>[10, 11, 12, 13, 14, 15, 16, 17, 19, 23, 24, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>387605</td>\n",
       "      <td>[4, 6, 13, 14, 22, 26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>387615</td>\n",
       "      <td>[0, 1, 2, 4, 55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>387643</td>\n",
       "      <td>[39, 40, 41, 42, 46, 47, 52]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>387644</td>\n",
       "      <td>[0, 1, 2, 3, 5, 9, 10, 11, 12, 14, 15, 16, 18,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17395</th>\n",
       "      <td>431987</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17396</th>\n",
       "      <td>431989</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17397</th>\n",
       "      <td>431991</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17398</th>\n",
       "      <td>431999</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17399</th>\n",
       "      <td>432020</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                      weeks_since_first_transaction\n",
       "0       387604  [10, 11, 12, 13, 14, 15, 16, 17, 19, 23, 24, 2...\n",
       "1       387605                             [4, 6, 13, 14, 22, 26]\n",
       "2       387615                                   [0, 1, 2, 4, 55]\n",
       "3       387643                       [39, 40, 41, 42, 46, 47, 52]\n",
       "4       387644  [0, 1, 2, 3, 5, 9, 10, 11, 12, 14, 15, 16, 18,...\n",
       "...        ...                                                ...\n",
       "17395   431987                                                [0]\n",
       "17396   431989                                                [0]\n",
       "17397   431991                                                [0]\n",
       "17398   431999                                                [0]\n",
       "17399   432020                                                [0]\n",
       "\n",
       "[17400 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by user_id get all the weeks_since_first_transaction values for each user and sort them in ascending order\n",
    "mastery_df_german.groupby('user_id').weeks_since_first_transaction.unique().reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0c82c52",
   "metadata": {},
   "source": [
    "To fix this, we change our week definition to be the \"active\" weeks (i.e. weeks that the user has done at least one kind of event) of a user. Meaning that in the case that a user solves some questions the first week then does not login to the platform for 5-6 weeks, and comes back, the 2nd week of that user will be considered the time where the user has returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1ad4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want to consider the active weeks of the users\n",
    "temp = mastery_df_german.groupby('user_id').weeks_since_first_transaction.apply(list)\n",
    "mastery_df_german = mastery_df_german.join(temp, on='user_id', how='left', rsuffix='_list')\n",
    "# update the weeks_since_first_transaction column to the index of the list\n",
    "mastery_df_german['weeks_since_first_transaction'] = mastery_df_german.apply(lambda x: x['weeks_since_first_transaction_list'].index(x['weeks_since_first_transaction']), axis=1)\n",
    "# drop the list column\n",
    "mastery_df_german = mastery_df_german.drop(columns=['weeks_since_first_transaction_list'])\n",
    "\n",
    "# We only want to consider the active weeks of the users\n",
    "temp = mastery_df_math.groupby('user_id').weeks_since_first_transaction.apply(list)\n",
    "mastery_df_math = mastery_df_math.join(temp, on='user_id', how='left', rsuffix='_list')\n",
    "# update the weeks_since_first_transaction column to the index of the list\n",
    "mastery_df_math['weeks_since_first_transaction'] = mastery_df_math.apply(lambda x: x['weeks_since_first_transaction_list'].index(x['weeks_since_first_transaction']), axis=1)\n",
    "# drop the list column\n",
    "mastery_df_math = mastery_df_math.drop(columns=['weeks_since_first_transaction_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which user id belongs to the maximum weeks_since_first_transaction just for visualization\n",
    "max_week = mastery_df_german.weeks_since_first_transaction.max()\n",
    "user_id = mastery_df_german[mastery_df_german['weeks_since_first_transaction']==max_week].user_id\n",
    "sns.lineplot(x='weeks_since_first_transaction', y='mastery', data=mastery_df_german[mastery_df_german['user_id']==user_id.values[0]])\n",
    "plt.title('Mastery level change for the user with maximum weeks since first transaction - German')\n",
    "plt.xlabel('Weeks Since First Transaction')\n",
    "plt.ylabel('Mastery')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which user id belongs to the maximum weeks_since_first_transaction just for visualization\n",
    "max_week = mastery_df_math.weeks_since_first_transaction.max()\n",
    "user_id = mastery_df_math[mastery_df_math['weeks_since_first_transaction']==max_week].user_id\n",
    "sns.lineplot(x='weeks_since_first_transaction', y='mastery', data=mastery_df_math[mastery_df_math['user_id']==user_id.values[0]])\n",
    "plt.title('Mastery level change for the user with maximum weeks since first transaction - Math')\n",
    "plt.xlabel('Weeks Since First Transaction')\n",
    "plt.ylabel('Mastery')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f7a46bc",
   "metadata": {},
   "source": [
    "Currently we have the dataframe that has users mastery level per week along with other features. But even if we are currently considering the active weeks of each user, there are still some users who have interacted with the platform so little that they don't serve much use for our case. These are the users who only have been in the platform for a few weeks and thus do not have sufficient data to be trained on. We drop these users in the below cell:\n",
    "\n",
    "We chose the minimum required interaction count to be 4 as this still leaves us with an acceptible amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126aadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This number below changes which type of users we will consider. We will consider users who have at least this amount of weeks of activity\n",
    "week_larger_than = 6\n",
    "\n",
    "# Find the max weeks since first transaction for each user\n",
    "max_weeks_math = mastery_df_math.groupby('user_id').weeks_since_first_transaction.max().reset_index()\n",
    "users_with_no_week_math = max_weeks_math[max_weeks_math.weeks_since_first_transaction < week_larger_than]\n",
    "# drop these users from mastery_df_2\n",
    "mastery_df_subset_math = mastery_df_math[~mastery_df_math.user_id.isin(users_with_no_week_math.user_id)]\n",
    "print(\"Dropping: \", users_with_no_week_math.user_id.nunique(), \" users from math.\")\n",
    "print(\"Unique user count left in math: \", mastery_df_subset_math.user_id.nunique())\n",
    "\n",
    "# Find the max weeks since first transaction for each user\n",
    "max_weeks_german = mastery_df_german.groupby('user_id').weeks_since_first_transaction.max().reset_index()\n",
    "users_with_no_week_german = max_weeks_german[max_weeks_german.weeks_since_first_transaction < week_larger_than]\n",
    "# drop these users from mastery_df_2\n",
    "mastery_df_subset_german = mastery_df_german[~mastery_df_german.user_id.isin(users_with_no_week_german.user_id)]\n",
    "print(\"Dropping: \", users_with_no_week_german.user_id.nunique(), \" users from german.\")\n",
    "print(\"Unique user count left in german: \", mastery_df_subset_german.user_id.nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "500c34c3",
   "metadata": {},
   "source": [
    "Now there is an interesting edge case left for our use case. There are some users even after interacting with the platform for multiple weeks, have obtained 0 mastery in the end. \n",
    "\n",
    "Because we are aiming to predict the mastery level, users who have obtained no mastery at all will not be helping us in this journey, and thus we drop them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max mastery level per user\n",
    "max_mastery_math = mastery_df_subset_math.groupby('user_id').mastery.max().reset_index()\n",
    "# Drop users with 0 mastery\n",
    "zero_mastery_math = max_mastery_math[max_mastery_math.mastery == 0]\n",
    "print(\"Dropping \", zero_mastery_math.shape[0], \" users with 0 mastery for math\")\n",
    "mastery_df_subset_math = mastery_df_subset_math[~mastery_df_subset_math.user_id.isin(zero_mastery_math.user_id)]\n",
    "\n",
    "# Find the max mastery level per user\n",
    "max_mastery_german = mastery_df_subset_german.groupby('user_id').mastery.max().reset_index()\n",
    "# Drop users with 0 mastery\n",
    "zero_mastery_german = max_mastery_german[max_mastery_german.mastery == 0]\n",
    "print(\"Dropping \", zero_mastery_german.shape[0], \" users with 0 mastery for german\")\n",
    "mastery_df_subset_german = mastery_df_subset_german[~mastery_df_subset_german.user_id.isin(zero_mastery_german.user_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d820b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "mastery_df_math[mastery_df_math.user_id == 387604]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820dd5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mastery_df_german[mastery_df_german.user_id == 387604]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average mastery for each week for the first weeks we decided above\n",
    "sns.lineplot(x='weeks_since_first_transaction', y='mastery', data=mastery_df_subset_math[mastery_df_subset_math.weeks_since_first_transaction < week_larger_than])\n",
    "plt.title('Average Mastery Level - Math')\n",
    "plt.xlabel('Weeks Since First Transaction')\n",
    "plt.ylabel('Mastery')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae242906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average mastery for each week for the first weeks we decided above\n",
    "sns.lineplot(x='weeks_since_first_transaction', y='mastery', data=mastery_df_subset_german[mastery_df_subset_german.weeks_since_first_transaction < week_larger_than])\n",
    "plt.title('Average Mastery Level - German')\n",
    "plt.xlabel('Weeks Since First Transaction')\n",
    "plt.ylabel('Mastery')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a96b9499",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85633adb-d317-4ee3-bf06-e9f82f589c41",
   "metadata": {
    "id": "85633adb-d317-4ee3-bf06-e9f82f589c41"
   },
   "source": [
    "## Task 2: Model Building\n",
    "\n",
    "Train a model for your research question. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20215f48",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed055b2f",
   "metadata": {},
   "source": [
    "#### Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e61d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, mean_absolute_error\n",
    "\n",
    "data = mastery_df_subset_math.fillna(0)\n",
    "\n",
    "WEEK_COUNT = 6\n",
    "\n",
    "# Filter the data to include rows with weeks_since_first_transaction <= Week count - 1\n",
    "filtered_data = data[data['weeks_since_first_transaction'] <= WEEK_COUNT - 1]\n",
    "\n",
    "# Filter the data again to get target rows with weeks_since_first_transaction = Week count\n",
    "target_data = data[data['weeks_since_first_transaction'] == WEEK_COUNT]\n",
    "\n",
    "# Define features and target variable for the regression\n",
    "X = filtered_data.drop(columns=['user_id', 'title', 'mastery'])\n",
    "y = filtered_data['mastery']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the models and their hyperparameters\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso()\n",
    "}\n",
    "\n",
    "alphas = np.logspace(-3, 3, 20)  # Regularization strengths for Ridge and Lasso\n",
    "\n",
    "# Perform grid search for each model\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'LinearRegression':\n",
    "        model.fit(X_train, y_train)\n",
    "        mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "        print(f\"{model_name} - Mean Squared Error: {mse}\")\n",
    "    else:\n",
    "        param_grid = {'alpha': alphas}\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring=make_scorer(mean_squared_error))\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_alpha = grid_search.best_params_['alpha']\n",
    "        best_model = grid_search.best_estimator_\n",
    "        mse = mean_squared_error(y_test, best_model.predict(X_test))\n",
    "        print(f\"{model_name} (alpha={best_alpha}) - Mean Squared Error: {mse}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ae20d3b",
   "metadata": {},
   "source": [
    "Initially, the data is preprocessed by filtering it according to the weeks_since_first_transaction column. The filtered_data dataframe comprises rows with weeks up to and including WEEK_COUNT - 1, while the target_data dataframe has rows with weeks equal to WEEK_COUNT.\n",
    "\n",
    "Subsequently, a grid search is conducted for Ridge and Lasso to identify the best alpha value for each model. For Linear Regression, as there are no hyperparameters to optimize, the model is directly fitted to the training set.\n",
    "\n",
    "As per the MSE values, Ridge Regression with an alpha of 1000 slightly outperforms Linear Regression, whereas Lasso Regression with an alpha of 233.572 lags behind. This indicates that Ridge Regression strikes a superior balance between model complexity and regularization, thereby offering better protection against overfitting in comparison to the other two models within this math dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "972f175d",
   "metadata": {},
   "source": [
    "#### Test Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8644212",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_X = target_data.drop(columns=['user_id', 'title', 'mastery'])\n",
    "target_y = target_data['mastery']\n",
    "\n",
    "# Perform grid search for each model and store the best models\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'LinearRegression':\n",
    "        model.fit(X_train, y_train)\n",
    "        best_models[model_name] = model\n",
    "    else:\n",
    "        param_grid = {'alpha': alphas}\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring=make_scorer(mean_squared_error))\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_alpha = grid_search.best_params_['alpha']\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate and print the MSE for each model on the target_data\n",
    "test_mse_math = []\n",
    "test_rmse_math = []\n",
    "test_mae_math = []\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred = model.predict(target_X)\n",
    "    mse = mean_squared_error(target_y, y_pred)\n",
    "    rmse = mean_squared_error(target_y, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(target_y, y_pred)\n",
    "\n",
    "    test_mse_math.append(mse)\n",
    "    test_rmse_math.append(rmse)\n",
    "    test_mae_math.append(mae)\n",
    "\n",
    "    if model_name == 'LinearRegression':\n",
    "        print(f\"{model_name} - Mean Squared Error: {mse}\")\n",
    "        print(f\"{model_name} - Root Mean Squared Error: {rmse}\")\n",
    "        print(f\"{model_name} - Mean Absolute Error: {mae}\")\n",
    "    else:\n",
    "        alpha = model.alpha\n",
    "        print(f\"{model_name} (alpha={alpha}) - Mean Squared Error: {mse}\")\n",
    "        print(f\"{model_name} (alpha={alpha}) - Root Mean Squared Error: {rmse}\")\n",
    "        print(f\"{model_name} (alpha={alpha}) - Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e01b099a",
   "metadata": {},
   "source": [
    "#### Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature names\n",
    "feature_names = target_X.columns.tolist()\n",
    "\n",
    "# Display coefficients of each model\n",
    "for model_name, model in best_models.items():\n",
    "    if hasattr(model, \"coef_\"):\n",
    "        print(f\"{model_name} coefficients:\")\n",
    "        for feature, coef in zip(feature_names, model.coef_):\n",
    "            print(f\"{feature}: {coef}\")\n",
    "    else:\n",
    "        print(f\"{model_name} does not have coefficients\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51a4d55a",
   "metadata": {},
   "source": [
    "Now we are evaluating the performance of the three best models (Linear Regression, Ridge Regression, and Lasso Regression) on the target_data, which contains rows with weeks_since_first_transaction equal to WEEK_COUNT.\n",
    "\n",
    "Based on these evaluation metrics, Ridge Regression with an alpha of 1000 again outperforms the other two models on the target_data. It has a lower MSE, RMSE, and MAE compared to Linear Regression and Lasso Regression. This suggests that Ridge Regression continues to provide a better balance between model complexity and regularization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7231b5b6",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "for idx, (model_name, model) in enumerate(best_models.items()):\n",
    "    y_pred = model.predict(target_X)\n",
    "\n",
    "    axs[idx].scatter(target_y, target_y, alpha=0.5, marker='o', color='blue', label='Real')\n",
    "    axs[idx].scatter(target_y, y_pred, alpha=0.5, marker='x', color='red', label='Predicted')\n",
    "    axs[idx].set_title(model_name)\n",
    "    axs[idx].set_xlabel('Real Mastery')\n",
    "    axs[idx].legend(loc='upper left')\n",
    "\n",
    "axs[0].set_ylabel('Predicted Mastery')\n",
    "plt.suptitle('Predicted Mastery vs Real Mastery - Math')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c3971be",
   "metadata": {},
   "source": [
    "#### German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b6b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mastery_df_subset_german.fillna(0)\n",
    "\n",
    "# Filter the data to include rows with weeks_since_first_transaction <= Week count - 1\n",
    "filtered_data = data[data['weeks_since_first_transaction'] <=  WEEK_COUNT - 1]\n",
    "\n",
    "# Filter the data again to get target rows with weeks_since_first_transaction = Week count\n",
    "target_data = data[data['weeks_since_first_transaction'] ==  WEEK_COUNT]\n",
    "\n",
    "# Define features and target variable for the regression\n",
    "X = filtered_data.drop(columns=['user_id', 'title', 'mastery'])\n",
    "y = filtered_data['mastery']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the models and their hyperparameters\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso()\n",
    "}\n",
    "\n",
    "alphas = np.logspace(-3, 3, 20)  # Regularization strengths for Ridge and Lasso\n",
    "\n",
    "# Perform grid search for each model\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'LinearRegression':\n",
    "        model.fit(X_train, y_train)\n",
    "        mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "        print(f\"{model_name} - Mean Squared Error: {mse}\")\n",
    "    else:\n",
    "        param_grid = {'alpha': alphas}\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring=make_scorer(mean_squared_error))\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_alpha = grid_search.best_params_['alpha']\n",
    "        best_model = grid_search.best_estimator_\n",
    "        mse = mean_squared_error(y_test, best_model.predict(X_test))\n",
    "        print(f\"{model_name} (alpha={best_alpha}) - Mean Squared Error: {mse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "906c7c5a",
   "metadata": {},
   "source": [
    "We have applied the same approach the German dataset. As per the MSE values, Ridge Regression with an alpha of 1000 slightly outperforms Linear Regression, whereas Lasso Regression with an alpha of 233.572 lags behind. This indicates that Ridge Regression strikes a superior balance between model complexity and regularization, thereby offering better protection against overfitting in comparison to the other two models within this german dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a30ff89a",
   "metadata": {},
   "source": [
    "#### Test Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c77306",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_X = target_data.drop(columns=['user_id', 'title', 'mastery'])\n",
    "target_y = target_data['mastery']\n",
    "\n",
    "# Perform grid search for each model and store the best models\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'LinearRegression':\n",
    "        model.fit(X_train, y_train)\n",
    "        best_models[model_name] = model\n",
    "    else:\n",
    "        param_grid = {'alpha': alphas}\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring=make_scorer(mean_squared_error))\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_alpha = grid_search.best_params_['alpha']\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate and print the MSE for each model on the target_data\n",
    "test_mse_german = []\n",
    "test_rmse_german = []\n",
    "test_mae_german = []\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred = model.predict(target_X)\n",
    "    mse = mean_squared_error(target_y, y_pred)\n",
    "    rmse = mean_squared_error(target_y, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(target_y, y_pred)\n",
    "\n",
    "    test_mse_german.append(mse)\n",
    "    test_rmse_german.append(rmse)\n",
    "    test_mae_german.append(mae)\n",
    "    if model_name == 'LinearRegression':\n",
    "        print(f\"{model_name} - Mean Squared Error: {mse}\")\n",
    "        print(f\"{model_name} - Root Mean Squared Error: {rmse}\")\n",
    "        print(f\"{model_name} - Mean Absolute Error: {mae}\")\n",
    "    else:\n",
    "        alpha = model.alpha\n",
    "        print(f\"{model_name} (alpha={alpha}) - Mean Squared Error: {mse}\")\n",
    "        print(f\"{model_name} (alpha={alpha}) - Root Mean Squared Error: {rmse}\")\n",
    "        print(f\"{model_name} (alpha={alpha}) - Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6006002",
   "metadata": {},
   "source": [
    "#### Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc58a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature names\n",
    "feature_names = target_X.columns.tolist()\n",
    "\n",
    "# Display coefficients of each model\n",
    "for model_name, model in best_models.items():\n",
    "    if hasattr(model, \"coef_\"):\n",
    "        print(f\"{model_name} coefficients:\")\n",
    "        for feature, coef in zip(feature_names, model.coef_):\n",
    "            print(f\"{feature}: {coef}\")\n",
    "    else:\n",
    "        print(f\"{model_name} does not have coefficients\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3b90ec1",
   "metadata": {},
   "source": [
    "At this point, we assess the performance of the top three models (Linear Regression, Ridge Regression, and Lasso Regression) using the target_data, which includes rows where weeks_since_first_transaction is equal to WEEK_COUNT.\n",
    "\n",
    "From the evaluation metrics, Linear Regression surpasses the other two models when applied to the target_data. It exhibits lower values for MSE, RMSE, and MAE in comparison to Ridge Regression and Lasso Regression. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bed3f92",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca6643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "for idx, (model_name, model) in enumerate(best_models.items()):\n",
    "    y_pred = model.predict(target_X)\n",
    "\n",
    "    axs[idx].scatter(target_y, target_y, alpha=0.5, marker='o', color='blue', label='Real')\n",
    "    axs[idx].scatter(target_y, y_pred, alpha=0.5, marker='x', color='red', label='Predicted')\n",
    "    axs[idx].set_title(model_name)\n",
    "    axs[idx].set_xlabel('Real Mastery')\n",
    "    axs[idx].legend(loc='upper left')\n",
    "\n",
    "axs[0].set_ylabel('Predicted Mastery')\n",
    "plt.suptitle('Predicted Mastery vs Real Mastery - German')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9656905a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5b8d6d4",
   "metadata": {},
   "source": [
    "### LSTM and GRU models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3b2b4fd",
   "metadata": {},
   "source": [
    "For LSTM and GRU models we created a **lstm_functions.py** script to define two deep learning models, an LSTM (Long Short-Term Memory) model and a GRU (Gated Recurrent Unit) model, along with a custom dataset class for loading and pre-processing the data. The models are intended to predict the mastery variable for a target week, given the input sequence of data from the preceding weeks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1b71590",
   "metadata": {},
   "source": [
    "#### Load Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f24b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\" # limiting to one GPU\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa15bfa7",
   "metadata": {},
   "source": [
    "### German"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6bb2a48",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "114a7cc0",
   "metadata": {},
   "source": [
    "##### Step 1: Creation of test and train dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a905ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0\n",
    "mastery_df_subset_german.fillna(0, inplace=True)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "mastery_df_subset_german[['diligence','num_questions', 'percentage_correct', 'num_review', 'num_view', 'ratio_window_visible']] = scaler.fit_transform(mastery_df_subset_german[['diligence', 'num_questions', 'percentage_correct', 'num_review', 'num_view', 'ratio_window_visible']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = mastery_df_subset_german['user_id'].unique()\n",
    "valid_user_ids = []\n",
    "\n",
    "for user_id in user_ids:\n",
    "    user_data = mastery_df_subset_german[mastery_df_subset_german['user_id'] == user_id]\n",
    "    if len(user_data) > 6:\n",
    "        valid_user_ids.append(user_id)\n",
    "\n",
    "valid_mastery_df_german = mastery_df_subset_german[mastery_df_subset_german['user_id'].isin(valid_user_ids)]\n",
    "\n",
    "train_user_ids, test_user_ids = train_test_split(valid_user_ids, test_size=0.2, random_state=42)\n",
    "train_df = valid_mastery_df_german[valid_mastery_df_german['user_id'].isin(train_user_ids)]\n",
    "test_df = valid_mastery_df_german[valid_mastery_df_german['user_id'].isin(test_user_ids)]\n",
    "\n",
    "print(\"Train data frame unique user count:\", train_df['user_id'].nunique())\n",
    "print(\"Test data frame unique user count:\", test_df['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670fdc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_functions import MasteryDataset\n",
    "\n",
    "train_dataset = MasteryDataset(train_df)\n",
    "test_dataset = MasteryDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f786e41",
   "metadata": {},
   "source": [
    "**MasteryDataset** class: This class is a custom PyTorch dataset that takes a pandas dataframe df and a target_week as input. The dataset is designed to provide the input sequences and corresponding target values for the LSTM and GRU models.\n",
    "- The **_get_filtered_user_ids** method filters out user_ids that have data for the target week.\n",
    "- The __getitem__ method returns an input sequence and the target value for a given index. It pads the input sequence with zeros if necessary to match the target week's length and creates tensors from the input sequence and target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc5af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_functions import LSTMModel\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_size = train_dataset[0][0].shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 4\n",
    "output_size = 1\n",
    "learning_rate = 0.0001\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size, device).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_params = np.sum(np.fromiter((p.numel() for p in model.parameters() if p.requires_grad), dtype=int))\n",
    "print(f'The model has {num_params:,} trainable parameters')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16644df6",
   "metadata": {},
   "source": [
    "**LSTMModel** class: This class defines an LSTM model that inherits from PyTorch's nn.Module class. It takes the input size, hidden size, number of layers, output size, and a device as input arguments.\n",
    "- The LSTM layers are defined using the nn.LSTM module with the given input size, hidden size, and number of layers.\n",
    "- Two fully connected linear layers (nn.Linear) are added after the LSTM layers.\n",
    "- The **forward** method takes an input tensor x, initializes the hidden and cell states h0 and c0, and passes the input through the LSTM layers, followed by the linear layers with a ReLU activation function in between."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59db75de",
   "metadata": {},
   "source": [
    "#### Step 2: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d69a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2ae1bb5",
   "metadata": {},
   "source": [
    "#### Step 3: Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "model.eval()\n",
    "predictions_german_lstm = []\n",
    "test_loss = 0\n",
    "num_test_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions_german_lstm.extend(outputs.cpu().numpy().tolist())\n",
    "\n",
    "real_values_german = test_df[test_df[\"weeks_since_first_transaction\"] == 6]\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(real_values_german[\"mastery\"], predictions_german_lstm)\n",
    "rmse = mean_squared_error(real_values_german[\"mastery\"], predictions_german_lstm, squared =False)\n",
    "mae = mean_absolute_error(real_values_german[\"mastery\"], predictions_german_lstm)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c936c1cd",
   "metadata": {},
   "source": [
    "After obtaining the predictions, the ground truth values for the test dataset are extracted from the test_df dataframe for rows where the weeks_since_first_transaction value is 6."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83fa7e5f",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "228c1cf1",
   "metadata": {},
   "source": [
    "##### Step 1: Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_functions import GRUModel\n",
    "model = GRUModel(input_size, hidden_size, num_layers, output_size, device).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_params = np.sum(np.fromiter((p.numel() for p in model.parameters() if p.requires_grad), dtype=int))\n",
    "print(f'The model has {num_params:,} trainable parameters')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64915cb9",
   "metadata": {},
   "source": [
    "**GRUModel** class: This class defines a GRU model, similar to the **LSTMModel** class, but it uses the nn.GRU module instead of the nn.LSTM module. The GRU model also inherits from PyTorch's nn.Module class and takes the same input arguments as the LSTM model.\n",
    "- The GRU layers are defined using the nn.GRU module with the given input size, hidden size, and number of layers.\n",
    "- Two fully connected linear layers (nn.Linear) are added after the GRU layers.\n",
    "- The forward method takes an input tensor x, initializes the hidden state h0, and passes the input through the GRU layers, followed by the linear layers with a ReLU activation function in between."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2d8bf11",
   "metadata": {},
   "source": [
    "##### Step 2: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d91557",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74ed215e",
   "metadata": {},
   "source": [
    "##### Step 3: Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9720f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions_german_gru = []\n",
    "test_loss = 0\n",
    "num_test_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions_german_gru.extend(outputs.cpu().numpy().tolist())\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(real_values_german[\"mastery\"], predictions_german_gru)\n",
    "rmse = mean_squared_error(real_values_german[\"mastery\"], predictions_german_gru, squared =False)\n",
    "mae = mean_absolute_error(real_values_german[\"mastery\"], predictions_german_gru)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dde75040",
   "metadata": {},
   "source": [
    "##### If all predictions are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [0] * len(test_dataset)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(real_values_german[\"mastery\"], predictions)\n",
    "rmse = mean_squared_error(real_values_german[\"mastery\"], predictions, squared =False)\n",
    "mae = mean_absolute_error(real_values_german[\"mastery\"], predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a371ff9c",
   "metadata": {},
   "source": [
    "The results presented above are based on a model that predicts all zeros for the test dataset, essentially serving as a naive baseline. The performance of this baseline model is evaluated using three metrics: \n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- Mean Absolute Error (MAE). \n",
    "\n",
    "With an MSE of 598.292, an RMSE of 24.460, and an MAE of 20.287, the baseline model demonstrates a significant error when predicting the 'mastery' variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77175d58",
   "metadata": {},
   "source": [
    "### Math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0b713d4",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d314915",
   "metadata": {},
   "source": [
    "#### Step 1: Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb1c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0\n",
    "mastery_df_subset_math.fillna(0, inplace=True)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "mastery_df_subset_math[['diligence', 'num_questions', 'percentage_correct', 'num_review', 'num_view', 'ratio_window_visible']] = scaler.fit_transform(mastery_df_subset_math[['diligence', 'num_questions', 'percentage_correct', 'num_review', 'num_view', 'ratio_window_visible']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dbd6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = mastery_df_subset_math['user_id'].unique()\n",
    "valid_user_ids = []\n",
    "\n",
    "for user_id in user_ids:\n",
    "    user_data = mastery_df_subset_math[mastery_df_subset_math['user_id'] == user_id]\n",
    "    if len(user_data) > 6:\n",
    "        valid_user_ids.append(user_id)\n",
    "\n",
    "valid_mastery_df_math = mastery_df_subset_math[mastery_df_subset_math['user_id'].isin(valid_user_ids)]\n",
    "\n",
    "train_user_ids, test_user_ids = train_test_split(valid_user_ids, test_size=0.2, random_state=42)\n",
    "train_df = valid_mastery_df_math[valid_mastery_df_math['user_id'].isin(train_user_ids)]\n",
    "test_df = valid_mastery_df_math[valid_mastery_df_math['user_id'].isin(test_user_ids)]\n",
    "\n",
    "print(\"Train data frame unique user count:\", train_df['user_id'].nunique())\n",
    "print(\"Test data frame unique user count:\", test_df['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e451eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_functions import MasteryDataset\n",
    "\n",
    "train_dataset = MasteryDataset(train_df)\n",
    "test_dataset = MasteryDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c992f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_functions import LSTMModel\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_size = train_dataset[0][0].shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 4\n",
    "output_size = 1\n",
    "learning_rate = 0.0001\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size, device).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_params = np.sum(np.fromiter((p.numel() for p in model.parameters() if p.requires_grad), dtype=int))\n",
    "print(f'The model has {num_params:,} trainable parameters')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "847e3bb0",
   "metadata": {},
   "source": [
    "#### Step 2: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a49e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f7303b3",
   "metadata": {},
   "source": [
    "#### Step 3: Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "model.eval()\n",
    "predictions_math_lstm = []\n",
    "test_loss = 0\n",
    "num_test_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions_math_lstm.extend(outputs.cpu().numpy().tolist())\n",
    "\n",
    "real_values_math = test_df[test_df[\"weeks_since_first_transaction\"] == 6]\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(real_values_math[\"mastery\"], predictions_math_lstm)\n",
    "rmse = mean_squared_error(real_values_math[\"mastery\"], predictions_math_lstm, squared =False)\n",
    "mae = mean_absolute_error(real_values_math[\"mastery\"], predictions_math_lstm)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49bd9766",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ae9667b",
   "metadata": {},
   "source": [
    "##### Step 1: Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4bd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_functions import GRUModel\n",
    "model = GRUModel(input_size, hidden_size, num_layers, output_size, device).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_params = np.sum(np.fromiter((p.numel() for p in model.parameters() if p.requires_grad), dtype=int))\n",
    "print(f'The model has {num_params:,} trainable parameters')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03e59b7f",
   "metadata": {},
   "source": [
    "##### Step 2: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6714ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04a2adf8",
   "metadata": {},
   "source": [
    "##### Step 3: Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6984cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions_math_gru = []\n",
    "test_loss = 0\n",
    "num_test_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions_math_gru.extend(outputs.cpu().numpy().tolist())\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(real_values_math[\"mastery\"], predictions_math_gru)\n",
    "rmse = mean_squared_error(real_values_math[\"mastery\"], predictions_math_gru, squared =False)\n",
    "mae = mean_absolute_error(real_values_math[\"mastery\"], predictions_math_gru)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45cd448e",
   "metadata": {},
   "source": [
    "##### If all predictions are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba2895",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [0] * len(test_dataset)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(real_values_math[\"mastery\"], predictions)\n",
    "rmse = mean_squared_error(real_values_math[\"mastery\"], predictions, squared =False)\n",
    "mae = mean_absolute_error(real_values_math[\"mastery\"], predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3fc9a9e",
   "metadata": {},
   "source": [
    "The results presented above are based on a model that predicts all zeros for the test dataset, essentially serving as a naive baseline. The performance of this baseline model is evaluated using three metrics: \n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- Mean Absolute Error (MAE). \n",
    "\n",
    "With an MSE of 392.008, an RMSE of 19.799, and an MAE of 15.227, the baseline model demonstrates a significant error when predicting the 'mastery' variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf1f7375",
   "metadata": {},
   "source": [
    "*Your discussion about your model training goes here*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a323eaaa",
   "metadata": {},
   "source": [
    "**DISCUSSION**: In the regression section, we initially focused on data preprocessing and filtering. The data was filtered based on the 'weeks_since_first_transaction' column to create two separate dataframes: one with rows where the weeks are less than or equal to WEEK_COUNT - 1 (filtered_data) and another with rows where the weeks equal WEEK_COUNT (target_data). Next, we defined the features and target variable for the regression task, excluding 'user_id', 'title', and 'mastery' columns from the feature set. The data was then split into training and testing sets using a 70/30 split.\n",
    "\n",
    "In the LSTM and GRU section, we first created a custom PyTorch dataset class, MasteryDataset, to handle the data preparation and processing for our time series data. This class is responsible for filtering valid user_ids, handling variable-length sequences by padding with zeros, and returning the input sequence (first six weeks) and target value (mastery at week 6) for each user.\n",
    "\n",
    "Next, we defined two PyTorch model classes: LSTMModel and GRUModel. Both classes contain an RNN layer (LSTM or GRU, respectively), followed by two linear layers with a ReLU activation function after the first linear layer. These models are designed to accept input sequences and output a single value representing the predicted mastery at week 6.\n",
    "\n",
    "After defining the models, we trained the LSTM model using the Mean Squared Error (MSE) loss as the objective function and the Adam optimizer. The model was evaluated on the test set using a DataLoader, which allowed us to process test data in batches. The evaluation metrics used for the LSTM model include Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and Mean Absolute Error (MAE).\n",
    "\n",
    "A similar process was carried out for the GRU model, using the same training parameters, evaluation metrics, and test set. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "290a14d6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3c9a655-cec9-4c57-aec7-7a982f57a3af",
   "metadata": {
    "id": "b3c9a655-cec9-4c57-aec7-7a982f57a3af"
   },
   "source": [
    "## Task 3: Model Evaluation\n",
    "In this task, you will use metrics to evaluate your model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ceddfab",
   "metadata": {},
   "source": [
    "**METRICS**\n",
    "\n",
    "Mean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE) are popular evaluation metrics for regression tasks because they provide valuable insights into the performance of a model in predicting continuous outcomes. Each of these metrics has its unique advantages and contributes to the overall understanding of model performance.\n",
    "\n",
    "- **Mean Squared Error (MSE)**: MSE measures the average squared difference between the predicted values and the actual values. By squaring the errors, MSE puts more emphasis on larger errors and penalizes them heavily. \n",
    "- **Mean Absolute Error (MAE)**: MAE calculates the average absolute difference between the predicted values and the actual values. This metric provides a more interpretable measure of the average error magnitude, as it is on the same scale as the target variable.\n",
    "- **Root Mean Squared Error (RMSE)**: This metric combines the sensitivity to large errors (as in MSE) with the interpretability of the error scale (as in MAE). RMSE represents the standard deviation of the residuals (prediction errors) and provides an easily understandable measure of the average error magnitude."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a52547c5",
   "metadata": {},
   "source": [
    "### Regression Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb52a448",
   "metadata": {},
   "source": [
    "#### Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff5dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot and compare the test performances of regressions\n",
    "reg_labels = ['Linear', 'Ridge', 'Lasso']\n",
    "\n",
    "#Mean Squared Error\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
    "axs[0].bar(reg_labels, test_mse_math, color=['darkblue', 'darkred', 'darkorange'])\n",
    "axs[0].set_title('MSE By Regression Type')\n",
    "axs[0].set_xlabel('Type of Regression')\n",
    "axs[0].set_ylabel('Mean Squared Error')\n",
    "\n",
    "#Root Mean Squared Error\n",
    "axs[1].bar(reg_labels, test_rmse_math, color=['darkblue', 'darkred', 'darkorange'])\n",
    "axs[1].set_title('RMSE By Regression Type')\n",
    "axs[1].set_xlabel('Type of Regression')\n",
    "axs[1].set_ylabel('Root Mean Squared Error')\n",
    "\n",
    "#Mean Absolute Error\n",
    "axs[2].bar(reg_labels, test_mae_math, color=['darkblue', 'darkred', 'darkorange'])\n",
    "axs[2].set_title('MAE By Regression Type')\n",
    "axs[2].set_xlabel('Type of Regression')\n",
    "axs[2].set_ylabel('Mean Absolute Error')\n",
    "\n",
    "plt.suptitle(\"Evaluation Metrics - Math\", fontsize = 14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "774172da",
   "metadata": {},
   "source": [
    "#### German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot and compare the test performances of regressions\n",
    "reg_labels = ['Linear', 'Ridge', 'Lasso']\n",
    "\n",
    "#Mean Squared Error\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
    "axs[0].bar(reg_labels, test_mse_german, color=['darkblue', 'darkred', 'darkorange'])\n",
    "axs[0].set_title('MSE')\n",
    "axs[0].set_xlabel('Type of Regression')\n",
    "axs[0].set_ylabel('Mean Squared Error')\n",
    "\n",
    "#Root Mean Squared Error\n",
    "axs[1].bar(reg_labels, test_rmse_german, color=['darkblue', 'darkred', 'darkorange'])\n",
    "axs[1].set_title('RMSE')\n",
    "axs[1].set_xlabel('Type of Regression')\n",
    "axs[1].set_ylabel('Root Mean Squared Error')\n",
    "\n",
    "#Mean Absolute Error\n",
    "axs[2].bar(reg_labels, test_mae_german, color=['darkblue', 'darkred', 'darkorange'])\n",
    "axs[2].set_title('MAE')\n",
    "axs[2].set_xlabel('Type of Regression')\n",
    "axs[2].set_ylabel('Mean Absolute Error')\n",
    "\n",
    "plt.suptitle(\"Evaluation Metrics - German\", fontsize = 14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43c188af",
   "metadata": {},
   "source": [
    "Following the data preparation, we experimented with three regression models: Linear Regression, Ridge Regression, and Lasso Regression. For Ridge and Lasso Regression, we performed a grid search to identify the optimal alpha (regularization strength) values for each model. The performance of each model was evaluated based on the Mean Squared Error (MSE) on the testing set. \n",
    "\n",
    "**Ridge Regression** with an alpha of 1000 demonstrated a slightly better performance compared to Linear Regression, while Lasso Regression with an alpha of 233.572 yielded the worst performance for Math dataset. \n",
    "\n",
    "In the German dataset, **Linear Regression** demonstrated a slightly better performance compared to Ridge Regression while Lasso Regression with an alpha of 233.572 yielded the worst performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "927b013c",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fad59ce",
   "metadata": {},
   "source": [
    "#### Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0d65c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Create a scatter plot\n",
    "ax1.scatter(real_values_math[\"mastery\"], predictions_math_lstm)\n",
    "ax1.set_xlabel(\"Real Values\")\n",
    "ax1.set_ylabel(\"Predicted Values\")\n",
    "ax1.set_title(\"Scatter plot of Real vs Predicted Mastery Values\")\n",
    "\n",
    "# Create a line plot\n",
    "ax2.plot(real_values_math[\"mastery\"].values, label=\"Real Values\")\n",
    "ax2.plot(predictions_math_lstm, label=\"Predicted Values\", linestyle=\"--\")\n",
    "ax2.set_xlabel(\"Sample Index\")\n",
    "ax2.set_ylabel(\"Mastery\")\n",
    "ax2.set_title(\"Line plot of Real vs Predicted Mastery Values\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle(\"LSTM - Math\", fontsize = 16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2956064",
   "metadata": {},
   "source": [
    "#### German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Create a scatter plot\n",
    "ax1.scatter(real_values_german[\"mastery\"], predictions_german_lstm)\n",
    "ax1.set_xlabel(\"Real Values\")\n",
    "ax1.set_ylabel(\"Predicted Values\")\n",
    "ax1.set_title(\"Scatter plot of Real vs Predicted Mastery Values\")\n",
    "\n",
    "# Create a line plot\n",
    "ax2.plot(real_values_german[\"mastery\"].values, label=\"Real Values\")\n",
    "ax2.plot(predictions_german_lstm, label=\"Predicted Values\", linestyle=\"--\")\n",
    "ax2.set_xlabel(\"Sample Index\")\n",
    "ax2.set_ylabel(\"Mastery\")\n",
    "ax2.set_title(\"Line plot of Real vs Predicted Mastery Values\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle(\"LSTM - German\", fontsize = 16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7352fb9b",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58c36d96",
   "metadata": {},
   "source": [
    "#### Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ca975",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Create a scatter plot\n",
    "ax1.scatter(real_values_math[\"mastery\"], predictions_math_gru)\n",
    "ax1.set_xlabel(\"Real Values\")\n",
    "ax1.set_ylabel(\"Predicted Values\")\n",
    "ax1.set_title(\"Scatter plot of Real vs Predicted Mastery Values\")\n",
    "\n",
    "# Create a line plot\n",
    "ax2.plot(real_values_math[\"mastery\"].values, label=\"Real Values\")\n",
    "ax2.plot(predictions_math_gru, label=\"Predicted Values\", linestyle=\"--\")\n",
    "ax2.set_xlabel(\"Sample Index\")\n",
    "ax2.set_ylabel(\"Mastery\")\n",
    "ax2.set_title(\"Line plot of Real vs Predicted Mastery Values\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle(\"GRU - Math\", fontsize = 16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb82fd35",
   "metadata": {},
   "source": [
    "#### German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f519034",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Create a scatter plot\n",
    "ax1.scatter(real_values_german[\"mastery\"], predictions_german_gru)\n",
    "ax1.set_xlabel(\"Real Values\")\n",
    "ax1.set_ylabel(\"Predicted Values\")\n",
    "ax1.set_title(\"Scatter plot of Real vs Predicted Mastery Values\")\n",
    "\n",
    "# Create a line plot\n",
    "ax2.plot(real_values_german[\"mastery\"].values, label=\"Real Values\")\n",
    "ax2.plot(predictions_german_gru, label=\"Predicted Values\", linestyle=\"--\")\n",
    "ax2.set_xlabel(\"Sample Index\")\n",
    "ax2.set_ylabel(\"Mastery\")\n",
    "ax2.set_title(\"Line plot of Real vs Predicted Mastery Values\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle(\"GRU - German\", fontsize = 16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f2e0640",
   "metadata": {},
   "source": [
    "**DISCUSSION**\n",
    "\n",
    "**MATH**\n",
    "\n",
    "Baseline model (Prediction of full 0s):\n",
    "- Mean Squared Error: 392.00874191510013\n",
    "- Root Mean Squared Error: 19.799210638687093\n",
    "- Mean Absolute Error: 15.227262151480423\n",
    "\n",
    "For the Math dataset, the LSTM and GRU models once again outperform the baseline model by a significant margin. The LSTM model yields a Mean Squared Error (MSE) of 18.17, a Root Mean Squared Error (RMSE) of 4.26, and a Mean Absolute Error (MAE) of 2.49. Meanwhile, the GRU model has an MSE of 20.40, an RMSE of 4.52, and an MAE of 2.68.\n",
    "\n",
    "In stark contrast, the baseline model demonstrates much higher error values, with an MSE of 392.01, an RMSE of 19.80, and an MAE of 15.23. The substantial improvement in prediction accuracy provided by the LSTM and GRU models can be attributed to their ability to effectively capture temporal patterns and dependencies in the dataset. These results further highlight the effectiveness of LSTM and GRU models for predicting mastery at week 6, in comparison to the baseline model.\n",
    "\n",
    "**GERMAN**\n",
    "\n",
    "Baseline Model (Prediction of full 0s):\n",
    "- Mean Squared Error: 598.2922590590904\n",
    "- Root Mean Squared Error: 24.460013472177206\n",
    "- Mean Absolute Error: 20.286615810758597\n",
    "\n",
    "In the German dataset, the LSTM and GRU models show significantly better performance than the baseline model. The LSTM model achieves a Mean Squared Error (MSE) of 21.73, a Root Mean Squared Error (RMSE) of 4.66, and a Mean Absolute Error (MAE) of 3.20. The GRU model has an MSE of 23.24, an RMSE of 4.82, and an MAE of 3.11.\n",
    "\n",
    "In comparison, the baseline model exhibits much higher error values, with an MSE of 598.29, an RMSE of 24.46, and an MAE of 20.29. This considerable difference in performance indicates that the LSTM and GRU models are more effective in predicting mastery at week 6 than the baseline model. Both LSTM and GRU models demonstrate their ability to capture temporal patterns and dependencies in the data, leading to substantially improved prediction accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2c36f63",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e49d1dad",
   "metadata": {},
   "source": [
    "## Task 4: Team Reflection\n",
    "Please describe the contributions of each team member to Milestone 4. Reflect on how you worked as team: what went well, what can be improved for the next milestone?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cde86a72",
   "metadata": {},
   "source": [
    "For this milestone, the members performed the following tasks:\n",
    "\n",
    "**Aybars Yazici:** Data exploration and preprocessing, extracting mastery levels and the majority of the features.\n",
    "\n",
    "**Ilker Gul:** Implementation of Regression, LSTM, and GRU models. Training, testing, and evaluating the models on the given dataset. Visualization of the results.\n",
    "\n",
    "**Can Kirimca:** Evaluation of the models and visualization of the results. Extraction of a few features and separating the user records into Math and German.\n",
    "\n",
    "Although different members worked on different components of the project, we frequently held meetings to discuss the intermediate results and consulted each member on each step. \n",
    "\n",
    "Since LSTM and GRU have large numbers of parameters, our main concern was that the amount of data might be insufficient to train those models. However, these models performed better than we expected and managed the capture the sequential patterns in our data, and as previously stated, they performed significantly better than regression models. One potential task for the future might be to perform data augmentation to train these models on larger data as we expect them to perform better on larger datasets.\n",
    "\n",
    "Furthermore, one of the possible reasons why the regressions performed poorly is that we need to find features that describe the patterns in the data. One of our strategies for the next milestone will be to explore the dataset further and extract more meaningful features to improve the predictive performance of each model used."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "m2-classtime-sciper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31c7147094e2ab9b754e5fd0e3f8fe157308d93b1bc81d0c80652891375826d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
